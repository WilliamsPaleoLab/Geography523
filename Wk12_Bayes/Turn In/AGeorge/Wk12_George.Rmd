---
title: "Week 12 Lab - George"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
bin.prob <- function(p,n,h){
  probab  <- factorial(n)*p^h*(1-p)^(n-h)/(factorial(h)*factorial(n-h))
}

normalizing.fun <- function(n,h,prior.n,prior.h){
  beta <- prior.n - prior.h+1
  prior.h <- prior.h+1
  nc <- factorial(n)*beta(h+prior.h,n-h+beta)/(factorial(h)*factorial(n-h)*beta(prior.h,beta))
}

posterior.fun <- function(probs,n,h,prior.n,prior.h){
  
  #define additional variables
  beta <- prior.n - prior.h+1
  alpha <- prior.h+1
  
  #Likelihiood
  L <- dbinom(h,n,probs)
  
  #Prior
  prior <- dbeta(probs,alpha,beta)
  prior <- prior/sum(prior)
  #normalizing constant
  nc <- factorial(n)*beta(h+alpha,n-h+beta)/(factorial(h)*factorial(n-h)*beta(alpha,beta))
  
  posterior <- L*prior/nc
  
  output <- data.frame(parameter=probs,Posterior=posterior,Prior=prior,Likelihood = L)
  matplot(output$parameter,output[,2:4],type='l',xlab='',ylab='')
  mtext(side=1,line=2.2,font=2,expression(Theta),cex=1)
  mtext(side=2,line=2.2,font=2,cex=1,'Probability')
  legend('topleft',col=1:3,lty=1:3,legend=c('Posterior','Prior','Likelihood'))
  return(output)
}
```

**Question 1**


*Equal number of coin flips for prior and likelihood:*
```{r}
# Observations for LIkelihood
n <- 20
h <- 15

# Coin flips for prior
prior.n <- 20
prior.h <-  10 

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```

The absolute number of coinflips does matter because it changes the weight given to prior and likelihood. The x-value of the mode is located exactly halfway between the prior and likelihood curve. The y-value is closer to the prior than the likelihood.
    
    
*No coin flips:*
```{r}
# Observations for LIkelihood
n <- 20
h <- 15

# Coin flips for prior
prior.n <- 0
prior.h <-  0 

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
The prior is flat, because I gave the model no prior data. The mode of the likelihood and posterior are the same, because there is no prior mean to influence the posterior.


*Half the data*
```{r}
# Observations for LIkelihood
n <- 20
h <- 15

# Coin flips for prior
prior.n <- 10
prior.h <-  5 

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
The posterior's mode is skewed towards the likelihood because there are more observations than prior information.


*Twice the data*
```{r}
# Observations for LIkelihood
n <- 20
h <- 15

# Coin flips for prior
prior.n <- 40
prior.h <- 20

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
Since there is a lot of prior data, the mode value is closer to the prior curve. The probability at the mode is higher than in the previous example, because the prior and the posterior have steeper curves.

**Question 2**
Change number of coin flips used as data (always keep the proportion of heads at 0.75*n)


*Only four coin flips*
```{r}
# Observations for LIkelihood
n <- 4
h <- 3

# Coin flips for prior
prior.n <- 20
prior.h <- 10

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
Because the number of observations for the likelihood is so low compared to the prior, the posterior curve strongly mimics the prior curve. The posterior mode is only pulled slightly to the right by the likelihood curve.


*Twice the number of prior flips*
```{r}
# Observations for LIkelihood
n <- 40
h <- 0.75*n

# Coin flips for prior
prior.n <- 20
prior.h <- 10

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
Since there are double the observations for the likelihood, the posterior mode is closer to the likelihood's. In addition, the posterior curve is sharp and the probability at the mode is relatively high, because of the disproportionate likelihood input.


*Five times the number of prior flips*
```{r}
# Observations for LIkelihood
n <- 100
h <- 0.75*n

# Coin flips for prior
prior.n <- 20
prior.h <- 10

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```

Since the observations for the likelihood are five times as many for the prior, the posterior curve is very similar to that of the likelihood. The posterior and likelihood modes are very close. The posterior curve is only pulled slightly to the left bu the prior curve.


*Divide your coin flips into two parts:*
20 flips then use the new posterior as prior and add an additional 20 coin flips â€“ compare this to 40 coin flips
```{r}
# Observations for LIkelihood
n <- 20
h <- 0.75*n

# Coin flips for prior
prior.n <- 20
prior.h <- 10

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```

```{r}
# Observations for LIkelihood
n <- 20
h <- 15

# Coin flips for prior
prior.n <- 40
prior.h <- 25

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```

*Comparison*
```{r}
# Observations for LIkelihood
n <- 40
h <- 0.75*n

# Coin flips for prior
prior.n <- 20
prior.h <- 10

probs <-  seq(0,1,0.01)

outp <- posterior.fun(probs=probs,
                      n = n,
                      h = h,
                      prior.n = prior.n,
                      prior.h = prior.h)
```
The mode for the test and for 40 coin flips is in the same place, ~0.67, because the totals for both end up being 40 heads out of 60 flips, which is 2/3 probability.




**2. Markov chain Monte Carlo sampling**

```{r}
# brings in packages
library(usmap)
library(dplyr)

#downloads us state pop data
data("statepop")

# creates vector of possible state #s
state_nums <- seq(from = 1, to = 51, by = 1)

# adds numbers to statepop dataframe
statepop <- cbind(statepop,state_nums)

# creates variables
current_state = 0
new_state = 0
current_pop = 0
new_pop = 0

# creates population sum variable
sum <- sum(statepop$pop_2015)

# Samples state number vector randomly for first current state
current_state <- sample(state_nums, size = 1)
#probability <- c(0,1)

i = 0

states_visited = NULL

while (i < 50000){
  i = i + 1
  
  # adds state to vector
  states_visited <- append(states_visited, current_state)
  
  # Samples state number vector randomly for new state
  new_state <- sample(state_nums, size = 1)

  # Assigns corresponding population data
  current_pop <- statepop[current_state,4]
  new_pop <- statepop[new_state,4]

  # Compares two states' pops
  ratio <- new_pop/current_pop
  
  # if ratio is >= 1, assign new state to current state
  if (ratio >= 1){
    current_state <- new_state
  }
  
  # else statement
  else{
    # Draws 1 or 2 based on weighted probability of new state's pop over current state's pop
    new_prob <- sample.int(n = 2, size = 1, prob = c(ratio, 1-ratio))
   
     # If new_prob == 1, assign the new state to current_state
     if (new_prob == 1){
      current_state <- new_state
    }
    
    # Otherwise, the current_state remains current_state
    else{
      current_state <- current_state
    }
  }
}

# Creates final table of states, state population, and proportions of the state pop and states visited
states_visited_rough <- table(states_visited)
states_visited_table <- as.data.frame(statepop$full)
states_visited_table <- cbind(states_visited_table,states_visited_rough)
states_visited_prop <- states_visited_table$Freq/50000
states_visited_table <- cbind(states_visited_table,states_visited_prop)
state_pop_prop <- statepop$pop_2015/sum
state_pop_prop_final <- format(round(state_pop_prop, 5), nsmall = 5)
states_visited_table <- cbind(states_visited_table,state_pop_prop_final)
states_visited_table <- dplyr::select(states_visited_table,-states_visited)
states_visited_table
```






